#!/usr/bin/env python3
"""
æµ‹è¯•Gemini 2.5 Flashçš„promptä¼˜åŒ–åŠŸèƒ½
"""

import os
from dotenv import load_dotenv

try:
    from google import genai
    from google.genai import types
except ImportError:
    print("âŒ éœ€è¦å®‰è£… google-genai åŒ…")
    print("è¿è¡Œ: pip install google-genai")
    exit(1)

def test_prompt_optimization():
    """æµ‹è¯•promptä¼˜åŒ–åŠŸèƒ½"""
    
    load_dotenv()
    api_key = os.getenv("GEMINI_API_KEY")
    
    if not api_key:
        print("âŒ GEMINI_API_KEY æœªé…ç½®")
        return
    
    print("ğŸ§ª Gemini 2.5 Flash Prompt ä¼˜åŒ–æµ‹è¯•")
    print("=" * 60)
    
    # æµ‹è¯•ç”¨çš„åŸå§‹prompts
    test_prompts = [
        "ç”Ÿæˆå¯çˆ±çš„å¡é€šå½¢è±¡",
        "ç¨‹åºå‘˜å¤´åƒ",
        "æ­å·å¼€å‘è€…",
        "GOSIMå¤§ä¼šå‚ä¸è€…",
        "ç§‘æŠ€æ„Ÿåè¶³çš„ç¨‹åºå‘˜å¡é€šå½¢è±¡ï¼Œä½“ç°å¼€æºç²¾ç¥"
    ]
    
    client = genai.Client(api_key=api_key)
    
    for i, original_prompt in enumerate(test_prompts, 1):
        print(f"\nğŸ¨ æµ‹è¯• {i}/{len(test_prompts)}")
        print(f"ğŸ“ åŸå§‹prompt: {original_prompt}")
        
        try:
            optimization_instruction = f"""
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIå›¾åƒç”Ÿæˆpromptä¼˜åŒ–ä¸“å®¶ã€‚è¯·å°†ä»¥ä¸‹ç”¨æˆ·è¾“å…¥çš„promptä¼˜åŒ–ä¸ºæ›´é€‚åˆå›¾åƒç”Ÿæˆçš„æè¿°ï¼š

ç”¨æˆ·åŸå§‹prompt: "{original_prompt}"

è¯·åŸºäºä»¥ä¸‹è¦æ±‚ä¼˜åŒ–ï¼š
1. ä¿æŒç”¨æˆ·çš„æ ¸å¿ƒæ„å›¾
2. é€‚åˆGOSIMå¼€å‘è€…å¤§ä¼šçš„åœºæ™¯ï¼ˆæ­å·ç§‘æŠ€æ°›å›´ï¼Œå¼€æºç²¾ç¥ï¼‰
3. æ·»åŠ å¡é€šé£æ ¼ç›¸å…³çš„ç»†èŠ‚æè¿°
4. çªå‡ºä¸“ä¸šç¨‹åºå‘˜å½¢è±¡
5. ä½¿ç”¨æ¸…æ™°ã€å…·ä½“çš„è§†è§‰æè¿°è¯æ±‡
6. é¿å…æ¨¡ç³Šæˆ–æŠ½è±¡çš„è¡¨è¾¾

è¯·åªè¿”å›ä¼˜åŒ–åçš„promptï¼Œä¸è¦åŒ…å«å…¶ä»–è§£é‡Šã€‚ä¼˜åŒ–åçš„promptåº”è¯¥åœ¨100-150å­—ä¹‹é—´ã€‚
"""
            
            contents = [
                types.Content(
                    role="user",
                    parts=[
                        types.Part.from_text(text=optimization_instruction),
                    ],
                ),
            ]
            
            generate_content_config = types.GenerateContentConfig(
                thinking_config=types.ThinkingConfig(
                    thinking_budget=0,
                ),
            )
            
            response = client.models.generate_content(
                model="gemini-2.5-flash-lite",
                contents=contents,
                config=generate_content_config,
            )
            
            if response and response.candidates:
                optimized_prompt = response.candidates[0].content.parts[0].text.strip()
                print(f"âœ… ä¼˜åŒ–æˆåŠŸ!")
                print(f"ğŸ¯ ä¼˜åŒ–åprompt: {optimized_prompt}")
                print(f"ğŸ“ é•¿åº¦: {len(optimized_prompt)} å­—ç¬¦")
            else:
                print("âŒ ä¼˜åŒ–å¤±è´¥: æ²¡æœ‰è¿”å›ç»“æœ")
                
        except Exception as e:
            print(f"âŒ ä¼˜åŒ–å¼‚å¸¸: {e}")
        
        print("-" * 60)
    
    print("\nğŸ‰ Promptä¼˜åŒ–æµ‹è¯•å®Œæˆ!")

if __name__ == "__main__":
    test_prompt_optimization()